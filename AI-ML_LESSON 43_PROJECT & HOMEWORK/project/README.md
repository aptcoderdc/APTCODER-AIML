Deep Q-Network (DQN) for Tic-Tac-Toe

## Overview
This project implements a Deep Q-Network (DQN) for playing the game of Tic-Tac-Toe. The DQN learns to make optimal moves by taking the current state of the game board as input and outputting the action (the index of the next move). The model is trained using reinforcement learning techniques.

## Concepts Covered
Reinforcement Learning
Deep Q-Network (DQN)
Neural Network Implementation
Adam Optimizer
Binary Crossentropy Loss
Model Training

## Required Libraries
NumPy
TensorFlow
Keras

## Setup
Clone this repository to your local machine.
Ensure you have Python and the required libraries installed.
Open the project directory in your preferred code editor.

## How to Run
Run the dqn_tic_tac_toe.py file to train the DQN model.
Once trained, the model will be saved as dqn_tic_tac_toe.h5.
You can then use the trained model to play Tic-Tac-Toe.

## Project Structure
dqn_tic_tac_toe.py: Main Python script for training the DQN model.
dqn_tic_tac_toe.h5: Trained DQN model saved in HDF5 format.
README.md: Overview, setup instructions, and usage guidelines.

## Usage
Train the DQN model by running the dqn_tic_tac_toe.py script.